# NeuroScan AI: Agentic Brain Tumor Segmentation & Diagnostics ðŸ§ ðŸ“‹

## Project Overview

**NeuroScan AI** is an end-to-end medical imaging pipeline that combines Deep Learning with Agentic AI to detect and analyze brain tumors from MRI scans. The system utilizes a custom U-Net architecture for high-precision segmentation and a Vision-Language Agent (Llama 4 Scout via Groq) to provide morphological diagnostics.

### Key Features

âœ… **Dual-Dataset Validation**: Trained on BraTS 2021 and cross-validated on BraTS 2019 for robust generalization  
âœ… **Multi-Agent Workflow**: Radiologist Agent (segmentation) + Consultant Agent (grading & reporting)  
âœ… **Medical Safety First**: Clinical False Positive rate of only **0.14%**  
âœ… **GPU Optimized**: Mixed Precision training for NVIDIA RTX 5060 Laptop GPUs  
âœ… **Real-time Inference**: ~25ms per MRI slice  

---

## ðŸ“Š Performance Metrics

| Metric | BraTS 2021 (Internal) | BraTS 2019 (External) | Status |
|--------|----------------------|----------------------|--------|
| **Mean Dice Score** | 0.9235 | 0.8510 | âœ… Verified |
| **Precision** | 94.07% | 89.12% | âœ… Verified |
| **Recall (Sensitivity)** | 83.88% | 78.45% | âœ… Verified |
| **False Positive Rate** | 0.14% | 0.29% | ðŸ”’ Safe |

**Generalization Gap**: Only 7.85% Dice drop across datasets (excellent cross-domain robustness)

---

## ðŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Model** | Custom 2D U-Net with Skip Connections |
| **Deep Learning** | PyTorch (Nightly Build) |
| **Web UI** | Streamlit |
| **Vision-Language Model** | Groq SDK (Llama 4 Scout) |
| **Medical Imaging** | Nibabel, Nilearn (NIfTI processing) |
| **Image Processing** | OpenCV, Albumentations |
| **GPU** | NVIDIA RTX 5060 Laptop (Mixed Precision) |

---

## ðŸ“‚ Project Structure

```
BrainTumor_AI/
â”œâ”€â”€ agent_app.py              # ðŸŽ¯ Streamlit Multi-Agent Diagnostic Interface
â”œâ”€â”€ model.py                  # ðŸ§  U-Net Architecture Definition
â”œâ”€â”€ dataset.py                # ðŸ“¦ BraTS Dataset Loader (DataLoader)
â”œâ”€â”€ train.py                  # ðŸ‹ï¸ Training Pipeline with Validation
â”œâ”€â”€ test_model.py             # âœ… Final Test Report Generation
â”œâ”€â”€ evaluate_2019.py          # ðŸ“Š Cross-Dataset Generalization Audit
â”œâ”€â”€ analyze_data.py           # ðŸ” Data Quality Visualization
â”œâ”€â”€ split_data.py             # ðŸ“‚ Train/Val/Test Split Script
â”œâ”€â”€ download_sample.py        # â¬‡ï¸ BraTS Dataset Downloader
â”‚
â”œâ”€â”€ my_checkpoint.pth.tar     # ðŸ’¾ Trained Model Weights (Dice: 0.92)
â”œâ”€â”€ requirements.txt          # ðŸ“‹ Python Dependencies
â”‚
â”œâ”€â”€ BraTS_Split/              # ðŸ“ Processed Dataset
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ results/                  # ðŸ“ˆ Final Evaluation Outputs
â”‚   â”œâ”€â”€ comparison_dice.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ generalization_histogram.png
â”‚   â””â”€â”€ Final_Report_Card.png
â”‚
â””â”€â”€ README.md                 # ðŸ“– This File
```

---

## ðŸš€ Getting Started

Data set: https://www.kaggle.com/datasets/dschettler8845/brats-2021-task1
testing data: https://www.kaggle.com/datasets/aryashah2k/brain-tumor-segmentation-brats-2019

### 1ï¸âƒ£ Installation

```bash
# Clone repository
git clone https://github.com/Sunny-Soni00/NeuroScan-AI
cd NeuroScanAI

# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Download & Prepare Data

```bash
# Download BraTS 2021 dataset (automatic)
python download_sample.py

# Split into train/val/test (80/10/10)
python split_data.py

# Visualize data quality
python analyze_data.py
```

### 3ï¸âƒ£ Train the Model (Optional)

```bash
# Start training from scratch (takes ~2-4 hours on RTX 5060)
python train.py

# Monitor validation metrics in real-time
```

### 4ï¸âƒ£ Launch the Diagnostic Interface

```bash
# Start Streamlit app
streamlit run agent_app.py

# Open browser â†’ http://localhost:8501
# Upload an MRI scan â†’ Get AI diagnosis
```

### 5ï¸âƒ£ Evaluate Model Performance

```bash
# Test on internal test set
python test_model.py

# Cross-validate on BraTS 2019 (generalization audit)
python evaluate_2019.py
```

---

## ðŸŽ¯ How It Works

### **Agent 1: Radiologist (Segmentation)**
- Receives MRI scan (256Ã—256 input)
- U-Net predicts tumor segmentation mask
- Calculates tumor area and location
- Outputs: Binary mask + morphological metrics

### **Agent 2: Consultant (Diagnosis)**
- Receives tumor mask + medical context
- Llama 4 Scout Vision Agent analyzes morphology
- Grades tumor aggressiveness (HGG/LGG)
- Outputs: Clinical report + confidence scores

---

## ðŸ“ˆ Key Results

### Generalization Analysis
```
BraTS 2021 (Training Set)
â”œâ”€ Mean Dice: 0.9235
â”œâ”€ Precision: 94.07%
â””â”€ Status: âœ… SOTA

BraTS 2019 (External Audit)
â”œâ”€ Mean Dice: 0.8510
â”œâ”€ Precision: 89.12%
â”œâ”€ Generalization Gap: -7.85%
â””â”€ Status: âœ… Excellent Cross-Domain Transfer
```

### Safety Metrics
- **True Negative Rate**: 98.71% (healthy tissue correctly identified)
- **False Positive Rate**: 0.14% (minimal false alarms)
- **Clinical Grade**: ðŸ”’ Safe for deployment

---

## âš™ï¸ Configuration

Edit these settings in `agent_app.py` or training scripts:

```python
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
IMG_SIZE = 256                    # Input image resolution
BATCH_SIZE = 16                   # Training batch size
LEARNING_RATE = 1e-4             # Adam optimizer LR
NUM_EPOCHS = 50                   # Training epochs
CHECKPOINT_PATH = "my_checkpoint.pth.tar"
```

---

## ðŸ“¦ Requirements

```txt
torch>=2.0.0
torchvision>=0.15.0
streamlit>=1.28.0
opencv-python>=4.8.0
numpy>=1.24.0
nibabel>=5.0.0
nilearn>=0.10.0
matplotlib>=3.7.0
pillow>=10.0.0
albumentations>=1.3.0
groq>=0.4.0
google-generativeai>=0.3.0
tqdm>=4.66.0
kagglehub>=0.2.0
```

Install all at once:
```bash
pip install -r requirements.txt
```

---

## ðŸ”¬ Model Architecture

```
Input (1, 256, 256)
    â†“
Encoder (4 levels)
    â”œâ”€ Conv 1Ã—1 â†’ 64 channels
    â”œâ”€ Conv 64 â†’ 128 (MaxPool)
    â”œâ”€ Conv 128 â†’ 256 (MaxPool)
    â””â”€ Conv 256 â†’ 512 (MaxPool)
    â†“
Bottleneck (512 â†’ 512)
    â†“
Decoder (4 levels)
    â”œâ”€ UpConv 512 â†’ 256 (Skip Connection)
    â”œâ”€ UpConv 256 â†’ 128 (Skip Connection)
    â”œâ”€ UpConv 128 â†’ 64 (Skip Connection)
    â””â”€ UpConv 64 â†’ 1 (Output)
    â†“
Sigmoid Activation
    â†“
Output: Probability Map (1, 256, 256)
```

**Parameters**: ~7.8M trainable weights

---

## ðŸš¨ Known Limitations & Future Work

| Limitation | Impact | Planned Fix |
|-----------|--------|------------|
| Micro-tumors (<50px) | Low sensitivity for small lesions | Attention-Gated U-Net |
| 2D Slices Only | Ignores volumetric context | 3D U-Net implementation |
| FLAIR Modality | Other MRI sequences not supported | Multi-modal fusion |
| Inference Latency | ~25ms per slice | Model quantization (INT8) |

---

## ðŸ“ Usage Example

```python
from PIL import Image
import streamlit as st

# In agent_app.py:
uploaded_file = st.file_uploader("Upload MRI Scan", type=["png", "jpg", "nii.gz"])

if uploaded_file:
    # Preprocessing
    img = Image.open(uploaded_file)
    
    # Agent 1: Segmentation
    tumor_mask = unet_model.predict(img)
    
    # Agent 2: Diagnosis
    report = groq_client.analyze_tumor(tumor_mask, img)
    
    st.write(report)  # Display clinical report
```