import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import os
from DRUnet.DRUnet_v2.model_drunet_v2 import AttentionDRUNet

# ================= ‚öôÔ∏è CONFIGURATION =================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "DRUnet/DRUnet_v2/results/v2_checkpoint.pth.tar"
IMG_SIZE = 256

# Page configuration
st.set_page_config(
    page_title="DRUnetv2 Brain Tumor AI | Segmentation",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS styling
st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .stButton>button {
        width: 100%;
        border-radius: 10px;
        height: 3em;
        background: linear-gradient(90deg, #00d4ff 0%, #0099ff 100%);
        color: white;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 15px rgba(0, 153, 255, 0.3);
        transition: transform 0.2s;
    }
    .stButton>button:hover {
        transform: scale(1.05);
    }
    .metric-box {
        padding: 20px;
        border-radius: 15px;
        background-color: rgba(255, 255, 255, 0.95);
        border-left: 5px solid #00d4ff;
        margin: 10px 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    }
    .prediction-section {
        background: rgba(255, 255, 255, 0.95);
        padding: 30px;
        border-radius: 15px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }
    .header-title {
        color: white;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        font-size: 3em;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

# ================= üß† MODEL LOADER =================
@st.cache_resource
def load_drunetv2_model():
    """Load DRUnetv2 model from checkpoint"""
    model = AttentionDRUNet(in_channels=3, out_channels=1).to(DEVICE)
    try:
        if os.path.exists(MODEL_PATH):
            checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
            model.load_state_dict(checkpoint)
            model.eval()
            return model
        else:
            st.error(f"‚ùå Model not found at: {MODEL_PATH}")
            return None
    except Exception as e:
        st.error(f"‚ùå Error loading model: {str(e)}")
        return None

drunetv2_model = load_drunetv2_model()

# ================= üõ†Ô∏è UTILITIES =================
def preprocess_image(image_path):
    """Load and preprocess image for 2.5D input"""
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    if image is None:
        return None, None, None
    
    # Resize to 256x256
    image_resized = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
    
    # Normalize
    if np.max(image_resized) > 0:
        image_norm = (image_resized - np.mean(image_resized)) / (np.std(image_resized) + 1e-8)
    else:
        image_norm = image_resized / 255.0
    
    # Create 2.5D stack (same slice 3 times for single image input)
    image_stack = np.stack([image_norm, image_norm, image_norm], axis=0)
    image_tensor = torch.tensor(image_stack, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    return image_tensor, image_resized, image

def predict_tumor(image_tensor):
    """Get model prediction"""
    with torch.no_grad():
        output = torch.sigmoid(drunetv2_model(image_tensor))
        pred_mask = (output > 0.5).float().squeeze().cpu().numpy()
    return pred_mask

def calculate_metrics(pred_mask, display_img):
    """Calculate tumor metrics"""
    tumor_pixels = np.sum(pred_mask > 0)
    total_pixels = pred_mask.shape[0] * pred_mask.shape[1]
    tumor_percentage = (tumor_pixels / total_pixels) * 100
    
    # Find bounding box
    contours, _ = cv2.findContours((pred_mask.astype(np.uint8) * 255), 
                                     cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    bbox = None
    if contours:
        c = max(contours, key=cv2.contourArea)
        bbox = cv2.boundingRect(c)
    
    return {
        'tumor_pixels': tumor_pixels,
        'tumor_percentage': tumor_percentage,
        'bbox': bbox,
        'total_pixels': total_pixels
    }

def create_overlay(original_img, pred_mask):
    """Create overlay visualization"""
    # Normalize original image
    img_display = cv2.cvtColor(original_img, cv2.COLOR_GRAY2BGR)
    img_display = cv2.normalize(img_display, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    # Create colored mask
    colored_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)
    colored_mask[:, :, 0] = (pred_mask * 255).astype(np.uint8)  # Red channel
    
    # Blend
    overlay = cv2.addWeighted(img_display, 0.7, colored_mask, 0.3, 0)
    
    return overlay

# ================= üñ•Ô∏è UI LAYOUT =================
# Header
col1, col2 = st.columns([3, 1])
with col1:
    st.markdown('<h1 class="header-title">üß† DRUnetv2 Brain Tumor Segmentation AI</h1>', 
                unsafe_allow_html=True)
    st.markdown('*Advanced Deep Learning for Precise Tumor Detection & Localization*')

with col2:
    st.info(f"üîß Device: **{DEVICE.upper()}**")

st.markdown("---")

# Sidebar
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063176.png", width=80)
    st.title("‚öôÔ∏è Settings")
    
    confidence_threshold = st.slider(
        "Prediction Confidence Threshold",
        0.3, 0.9, 0.5, 0.05,
        help="Adjust sensitivity of tumor detection"
    )
    
    st.markdown("---")
    st.subheader("üìä Model Info")
    st.caption("**Architecture**: Attention-Guided Deep Residual U-Net")
    st.caption("**Input**: 2.5D MRI Stack (256√ó256√ó3)")
    st.caption("**Dice Score**: 90.37% (BraTS 2021)")
    st.caption("**Generalization**: 83.03% (BraTS 2019)")
    st.markdown("---")
    
    if st.button("‚ÑπÔ∏è About This Model", use_container_width=True):
        st.info("""
        **DRUnetv2** combines multiple advanced techniques:
        - **2.5D Input**: Spatial context from adjacent slices
        - **Attention Gates**: Suppress background noise
        - **Hybrid Loss**: Focal + Dice for hard cases
        - **Test-Time Augmentation**: Robust predictions
        """)

# Main content
tab1, tab2, tab3 = st.tabs(["üéØ Prediction", "üìä Analysis", "‚ÑπÔ∏è Guide"])

with tab1:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üì§ Upload MRI Scan")
        uploaded_file = st.file_uploader(
            "Upload a brain MRI image (PNG, JPG)",
            type=["png", "jpg", "jpeg"],
            help="Grayscale or color MRI images accepted"
        )
    
    with col2:
        st.subheader("üìù Instructions")
        st.markdown("""
        1. **Upload** a brain MRI scan
        2. **Click** "Run Prediction"
        3. **View** results and metrics
        4. **Download** visualization
        """)
    
    if uploaded_file is not None and drunetv2_model is not None:
        # Save uploaded file temporarily
        with open("temp_upload.png", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Process image
        image_tensor, display_img, original_img = preprocess_image("temp_upload.png")
        
        if image_tensor is not None:
            st.markdown("---")
            
            # Prediction button
            if st.button("üöÄ Run Tumor Prediction", use_container_width=True, type="primary"):
                with st.spinner('üîÑ Processing... Analyzing MRI scan...'):
                    # Get prediction
                    pred_mask = predict_tumor(image_tensor)
                    
                    # Calculate metrics
                    metrics = calculate_metrics(pred_mask, display_img)
                    
                    # Create overlay
                    overlay = create_overlay(display_img, pred_mask)
                    
                    st.success("‚úÖ Prediction Complete!")
                    st.markdown("---")
                    
                    # Display results in 3 columns
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image(display_img, caption="üì∏ Original MRI", use_column_width=True, 
                                clamp=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image((pred_mask * 255).astype(np.uint8), 
                                caption="üéØ Tumor Segmentation Mask", use_column_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image(overlay, caption="üîó Overlay View", use_column_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Metrics section
                    st.markdown("---")
                    st.subheader("üìà Tumor Analysis Metrics")
                    
                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                    
                    with metric_col1:
                        st.markdown(f"""
                        <div class="metric-box">
                            <h3 style="color: #00d4ff; margin: 0;">Tumor Area</h3>
                            <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                                {metrics['tumor_pixels']:,} px
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with metric_col2:
                        st.markdown(f"""
                        <div class="metric-box">
                            <h3 style="color: #00d4ff; margin: 0;">Coverage %</h3>
                            <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                                {metrics['tumor_percentage']:.2f}%
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with metric_col3:
                        st.markdown(f"""
                        <div class="metric-box">
                            <h3 style="color: #00d4ff; margin: 0;">Confidence</h3>
                            <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                                {(1 - np.std(pred_mask)) * 100:.1f}%
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with metric_col4:
                        tumor_status = "‚ö†Ô∏è Detected" if metrics['tumor_pixels'] > 100 else "‚úÖ Clear"
                        st.markdown(f"""
                        <div class="metric-box">
                            <h3 style="color: #00d4ff; margin: 0;">Status</h3>
                            <p style="font-size: 20px; color: #667eea; margin: 10px 0;">
                                {tumor_status}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Download button
                    st.markdown("---")
                    from io import BytesIO
                    
                    fig_pil = Image.fromarray((overlay * 1).astype(np.uint8))
                    buf = BytesIO()
                    fig_pil.save(buf, format="PNG")
                    buf.seek(0)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button(
                            label="‚¨áÔ∏è Download Prediction Mask",
                            data=buf.getvalue(),
                            file_name="tumor_prediction.png",
                            mime="image/png",
                            use_container_width=True
                        )
                    
                    # Cleanup
                    os.remove("temp_upload.png")
        else:
            st.error("‚ùå Could not process uploaded image. Please check the file format.")
    
    elif uploaded_file is None:
        st.info("üëà Please upload an MRI scan to get started!")
    else:
        st.error("‚ùå Model not loaded. Please check the model path.")

with tab2:
    st.subheader("üìä Understanding the Results")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### Tumor Area (Pixels)
        - Number of pixels identified as tumor
        - Higher values indicate larger tumors
        
        ### Coverage Percentage
        - Percentage of image containing tumor
        - Used to assess tumor extent
        
        ### Confidence Score
        - Based on prediction consistency
        - Higher = more confident prediction
        """)
    
    with col2:
        st.markdown("""
        ### Status
        - **‚úÖ Clear**: No significant tumor detected
        - **‚ö†Ô∏è Detected**: Tumor present in scan
        
        ### Overlay View
        - **Gray**: Original MRI
        - **Red**: Predicted tumor region
        - Shows spatial relationship
        """)

with tab3:
    st.subheader("üéì How to Use DRUnetv2")
    
    st.markdown("""
    ### Step-by-Step Guide
    
    **1. Prepare Your MRI Scan**
    - Use FLAIR, T1, T2, or T1c modalities
    - Image should be 256√ó256 or larger
    - Grayscale or color images work
    
    **2. Upload the Image**
    - Click the upload area
    - Select your MRI scan file
    - Supported formats: PNG, JPG, JPEG
    
    **3. Run Prediction**
    - Click "üöÄ Run Tumor Prediction"
    - Wait for analysis (typically 2-3 seconds)
    
    **4. Interpret Results**
    - View the three side-by-side images
    - Check the metrics for tumor statistics
    - Download the prediction if needed
    
    ### Key Features of DRUnetv2
    
    ‚ú® **2.5D Spatial Context**: Uses adjacent slices for better accuracy
    
    üéØ **Attention Mechanisms**: Focuses on tumor regions, ignores background
    
    üìà **High Accuracy**: 90.37% Dice Score on validation set
    
    üåç **Strong Generalization**: 83% accuracy on external dataset (BraTS 2019)
    
    ‚ö° **Fast Inference**: GPU-optimized for quick predictions
    """)
    
    st.info("""
    **üìå Medical Disclaimer**: This AI tool is for research purposes only. 
    Always consult with qualified medical professionals for diagnosis and treatment decisions.
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>üß† DRUnetv2 Brain Tumor Segmentation | Built with Streamlit & PyTorch</p>
    <p>Powered by Attention-Guided Deep Residual U-Net Architecture</p>
</div>
""", unsafe_allow_html=True)
