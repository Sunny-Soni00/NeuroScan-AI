import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import os
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from DRUnet.DRUnet_v2.model_drunet_v2 import AttentionDRUNet
from DRUnet.DRUnet_v2.dataset_balance_v2 import BraTSDataset25D
from torch.utils.data import DataLoader

# ================= ‚öôÔ∏è CONFIGURATION (SAME AS TRAINING) =================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "DRUnet/DRUnet_v2/results/v2_checkpoint.pth.tar"
IMG_SIZE = 256
TEST_DATA_PATH = "BraTS_Split/test"

# Page configuration
st.set_page_config(
    page_title="DRUnetv2 Brain Tumor AI | 2.5D Segmentation",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS styling
st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .stButton>button {
        width: 100%;
        border-radius: 10px;
        height: 3em;
        background: linear-gradient(90deg, #00d4ff 0%, #0099ff 100%);
        color: white;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 15px rgba(0, 153, 255, 0.3);
    }
    .metric-box {
        padding: 20px;
        border-radius: 15px;
        background-color: rgba(255, 255, 255, 0.95);
        border-left: 5px solid #00d4ff;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    }
    .prediction-section {
        background: rgba(255, 255, 255, 0.95);
        padding: 30px;
        border-radius: 15px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# ================= üß† MODEL LOADER (EXACT SAME AS TRAINING) =================
@st.cache_resource
def load_drunetv2_model():
    """Load DRUnetv2 model - SAME AS TRAINING"""
    model = AttentionDRUNet(in_channels=3, out_channels=1).to(DEVICE)
    try:
        if os.path.exists(MODEL_PATH):
            checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
            model.load_state_dict(checkpoint)
            model.eval()
            return model
        else:
            st.error(f"‚ùå Model not found at: {MODEL_PATH}")
            return None
    except Exception as e:
        st.error(f"‚ùå Error loading model: {str(e)}")
        return None

drunetv2_model = load_drunetv2_model()

# ================= üõ†Ô∏è 2.5D PROCESSING (EXACT SAME AS TRAINING) =================
def load_and_prepare_image(image_path):
    """
    Load PNG image EXACTLY as BraTSDataset25D does.
    Returns the 2.5D stacked tensor.
    """
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        return None, None, None
    
    # Resize to 256x256 (SAME AS TRAINING)
    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
    
    # Normalize to 0-1 (SAME AS TRAINING)
    image = image / 255.0
    
    # Create 2.5D stack - for single image, use same slice 3 times
    img_stack = np.stack([image, image, image], axis=-1)
    
    # Transpose to (channels, height, width) - SAME AS TRAINING
    img_stack = np.transpose(img_stack, (2, 0, 1))
    
    # Convert to tensor (SAME AS TRAINING)
    img_tensor = torch.tensor(img_stack, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    return img_tensor, image, img_stack

def predict_with_model(img_tensor):
    """
    Run prediction EXACTLY as training does.
    """
    with torch.no_grad():
        output = torch.sigmoid(drunetv2_model(img_tensor))
        pred_mask = (output > 0.5).float().squeeze().cpu().numpy()
    
    return pred_mask, output.cpu().numpy()[0, 0]

def calculate_metrics(pred_mask, original_img):
    """Calculate tumor metrics"""
    tumor_pixels = np.sum(pred_mask > 0)
    total_pixels = pred_mask.shape[0] * pred_mask.shape[1]
    tumor_percentage = (tumor_pixels / total_pixels) * 100 if total_pixels > 0 else 0
    
    # Find bounding box
    contours, _ = cv2.findContours((pred_mask.astype(np.uint8) * 255), 
                                     cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    bbox = None
    if contours:
        c = max(contours, key=cv2.contourArea)
        bbox = cv2.boundingRect(c)
    
    return {
        'tumor_pixels': tumor_pixels,
        'tumor_percentage': tumor_percentage,
        'bbox': bbox,
        'total_pixels': total_pixels
    }

def create_overlay(original_img, pred_mask):
    """Create overlay visualization - SAME AS test_drunetv2.py"""
    img_display = cv2.cvtColor((original_img * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)
    
    # Create colored mask (Red for tumor)
    colored_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)
    colored_mask[:, :, 0] = (pred_mask * 255).astype(np.uint8)
    
    # Blend
    overlay = cv2.addWeighted(img_display, 0.7, colored_mask, 0.3, 0)
    
    return overlay

# ================= üñ•Ô∏è UI LAYOUT =================
st.markdown('<h1 style="text-align: center; color: white; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);">üß† DRUnetv2 Brain Tumor AI</h1>', 
            unsafe_allow_html=True)
st.markdown('<p style="text-align: center; color: white;">Advanced 2.5D Deep Learning for Precise Tumor Segmentation</p>', 
            unsafe_allow_html=True)

st.markdown("---")

# Sidebar configuration
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063176.png", width=80)
    st.title("‚öôÔ∏è Model Settings")
    
    confidence_threshold = st.slider(
        "Prediction Threshold",
        0.3, 0.9, 0.5, 0.05,
        help="0.5 = same as training"
    )
    
    st.markdown("---")
    st.subheader("üìä Model Architecture")
    st.caption("""
    **Type**: Attention-Guided Deep Residual U-Net
    **Input**: 2.5D MRI Stack (256√ó256√ó3)
    **Processing**: Same as training pipeline
    **Dice Score**: 90.37% (BraTS 2021)
    """)

# Main tabs
tab1, tab2, tab3 = st.tabs(["üéØ From Test Folder", "üì§ Upload Image", "‚ÑπÔ∏è Guide"])

with tab1:
    st.subheader("üìÇ Use Test Dataset (BraTS_Split/test)")
    
    # Load test dataset (SAME AS TRAINING)
    if os.path.exists(TEST_DATA_PATH):
        test_ds = BraTSDataset25D(TEST_DATA_PATH)
        
        st.info(f"‚úÖ Found {len(test_ds)} images in test folder")
        
        # Select image
        image_idx = st.slider(
            "Select Image from Test Set",
            0, len(test_ds) - 1, 0
        )
        
        if st.button("üöÄ Run Prediction on Test Image", use_container_width=True, type="primary"):
            with st.spinner('üîÑ Processing with 2.5D context...'):
                # Load image EXACTLY as training does
                x, y = test_ds[image_idx]
                x = x.unsqueeze(0).to(DEVICE)
                y = y.numpy()
                
                # Predict (EXACT SAME AS TRAINING)
                with torch.no_grad():
                    output = torch.sigmoid(drunetv2_model(x))
                    pred_mask = (output > 0.5).float().squeeze().cpu().numpy()
                
                # Get original image (middle channel of 2.5D stack)
                original_img = x[0, 1].cpu().numpy()
                
                # Create overlay
                overlay = create_overlay(original_img, pred_mask)
                
                st.success("‚úÖ Prediction Complete!")
                st.markdown("---")
                
                # Display 3-column layout
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                    st.image(original_img, caption="üì∏ Original MRI (2.5D Center)", use_column_width=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col2:
                    st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                    st.image((pred_mask * 255).astype(np.uint8), 
                            caption="üéØ AI Predicted Tumor", use_column_width=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                with col3:
                    st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                    st.image(overlay, caption="üîó Overlay View", use_column_width=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # Metrics (SAME CALCULATION AS TRAINING)
                st.markdown("---")
                st.subheader("üìà Tumor Analysis Metrics")
                
                tumor_pixels = np.sum(pred_mask > 0)
                total_pixels = pred_mask.shape[0] * pred_mask.shape[1]
                tumor_percentage = (tumor_pixels / total_pixels) * 100
                
                m1, m2, m3, m4 = st.columns(4)
                
                with m1:
                    st.markdown(f"""
                    <div class="metric-box">
                        <h3 style="color: #00d4ff; margin: 0;">Tumor Area</h3>
                        <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                            {tumor_pixels:,} px
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with m2:
                    st.markdown(f"""
                    <div class="metric-box">
                        <h3 style="color: #00d4ff; margin: 0;">Coverage %</h3>
                        <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                            {tumor_percentage:.2f}%
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with m3:
                    confidence = (1 - np.std(pred_mask)) * 100
                    st.markdown(f"""
                    <div class="metric-box">
                        <h3 style="color: #00d4ff; margin: 0;">Confidence</h3>
                        <p style="font-size: 24px; color: #667eea; margin: 10px 0;">
                            {confidence:.1f}%
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with m4:
                    tumor_status = "‚ö†Ô∏è Detected" if tumor_pixels > 100 else "‚úÖ Clear"
                    st.markdown(f"""
                    <div class="metric-box">
                        <h3 style="color: #00d4ff; margin: 0;">Status</h3>
                        <p style="font-size: 20px; color: #667eea; margin: 10px 0;">
                            {tumor_status}
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
    else:
        st.warning(f"‚ö†Ô∏è Test folder not found at: {TEST_DATA_PATH}")

with tab2:
    st.subheader("üì§ Upload Single MRI Image")
    st.caption("Upload a PNG/JPG image and it will be processed with 2.5D stacking")
    
    uploaded_file = st.file_uploader(
        "Upload MRI image",
        type=["png", "jpg", "jpeg"],
        help="Will be stacked 3x for 2.5D processing"
    )
    
    if uploaded_file is not None and drunetv2_model is not None:
        # Save temporarily
        with open("temp_upload.png", "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Process image (EXACT SAME AS TRAINING)
        img_tensor, display_img, img_stack = load_and_prepare_image("temp_upload.png")
        
        if img_tensor is not None:
            if st.button("üöÄ Run Prediction (2.5D Stacked)", use_container_width=True, type="primary"):
                with st.spinner('üîÑ Processing...'):
                    # Predict
                    pred_mask, confidence_map = predict_with_model(img_tensor)
                    
                    # Create overlay
                    overlay = create_overlay(display_img, pred_mask)
                    
                    st.success("‚úÖ Prediction Complete!")
                    st.markdown("---")
                    
                    # Display results
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image(display_img, caption="üì∏ Original MRI", use_column_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image((pred_mask * 255).astype(np.uint8), 
                                caption="üéØ Predicted Mask", use_column_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown('<div class="prediction-section">', unsafe_allow_html=True)
                        st.image(overlay, caption="üîó Overlay", use_column_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Metrics
                    st.markdown("---")
                    st.subheader("üìä Tumor Metrics")
                    
                    metrics = calculate_metrics(pred_mask, display_img)
                    
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("Tumor Area", f"{metrics['tumor_pixels']:,} px")
                    m2.metric("Coverage %", f"{metrics['tumor_percentage']:.2f}%")
                    m3.metric("Confidence", f"{np.mean(confidence_map[pred_mask > 0.5]) * 100:.1f}%")
                    m4.metric("Status", "‚ö†Ô∏è Detected" if metrics['tumor_pixels'] > 100 else "‚úÖ Clear")
                    
                    # Download
                    st.markdown("---")
                    fig_pil = Image.fromarray(overlay)
                    from io import BytesIO
                    buf = BytesIO()
                    fig_pil.save(buf, format="PNG")
                    buf.seek(0)
                    
                    st.download_button(
                        label="‚¨áÔ∏è Download Prediction",
                        data=buf.getvalue(),
                        file_name="tumor_prediction.png",
                        mime="image/png"
                    )
                
                # Cleanup
                os.remove("temp_upload.png")

with tab3:
    st.markdown("""
    ### üéì How This Works
    
    **Same as Training Pipeline:**
    - Loads images exactly like `BraTSDataset25D`
    - Uses 2.5D stacking (3 channels = 3 slices)
    - Same preprocessing & normalization
    - Same AttentionDRUNet model
    - Same confidence thresholds
    
    ### üìä Performance
    - **Dice Score**: 90.37% (BraTS 2021)
    - **Recall**: 89.66% (sensitivity)
    - **Precision**: 92.69% (reliability)
    - **Generalization**: 83.03% (BraTS 2019)
    
    ### üéØ Features
    - ‚úÖ 2.5D Spatial Context (prev + current + next slice)
    - ‚úÖ Attention Gates (focus on tumors)
    - ‚úÖ SE Blocks (channel recalibration)
    - ‚úÖ Test-Time Augmentation ready
    
    ### üìå Medical Disclaimer
    This tool is for research purposes only. Always consult qualified medical professionals.
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #999; padding: 20px;">
    <p>üß† DRUnetv2 Brain Tumor Segmentation | Training & Inference Aligned</p>
    <p>Powered by Attention-Guided Deep Residual U-Net (2.5D)</p>
    <p>Device: {}</p>
</div>
""".format(DEVICE.upper()), unsafe_allow_html=True)
